{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_cardinality</th>\n",
       "      <th>left_cardinality_ratio</th>\n",
       "      <th>base_cardinality</th>\n",
       "      <th>selectivity_on_indexed_attr</th>\n",
       "      <th>left_ordered</th>\n",
       "      <th>base_ordered</th>\n",
       "      <th>result_size</th>\n",
       "      <th>sel_on_indexed_attr_with_join_predicate</th>\n",
       "      <th>hj_idx_cost</th>\n",
       "      <th>hj_seq_cost</th>\n",
       "      <th>nl_idx_cost</th>\n",
       "      <th>nl_seq_cost</th>\n",
       "      <th>mj_idx_cost</th>\n",
       "      <th>mj_seq_cost</th>\n",
       "      <th>optimal_decision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10800</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>30000</td>\n",
       "      <td>0.908900</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9816</td>\n",
       "      <td>0.454467</td>\n",
       "      <td>3078.65</td>\n",
       "      <td>2821.50</td>\n",
       "      <td>5701.00</td>\n",
       "      <td>4.418208e+06</td>\n",
       "      <td>2197.32</td>\n",
       "      <td>3906.91</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3265</td>\n",
       "      <td>0.108833</td>\n",
       "      <td>30000</td>\n",
       "      <td>0.671800</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2193</td>\n",
       "      <td>0.335900</td>\n",
       "      <td>1188.48</td>\n",
       "      <td>1172.10</td>\n",
       "      <td>3383.99</td>\n",
       "      <td>9.879785e+05</td>\n",
       "      <td>1207.18</td>\n",
       "      <td>2656.47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4860</td>\n",
       "      <td>0.162000</td>\n",
       "      <td>30000</td>\n",
       "      <td>0.562533</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2734</td>\n",
       "      <td>0.281267</td>\n",
       "      <td>1002.33</td>\n",
       "      <td>1142.52</td>\n",
       "      <td>3874.45</td>\n",
       "      <td>1.231189e+06</td>\n",
       "      <td>1170.05</td>\n",
       "      <td>2504.54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7892</td>\n",
       "      <td>0.263067</td>\n",
       "      <td>30000</td>\n",
       "      <td>0.692467</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5465</td>\n",
       "      <td>0.346233</td>\n",
       "      <td>1237.22</td>\n",
       "      <td>1229.92</td>\n",
       "      <td>4806.79</td>\n",
       "      <td>2.460164e+06</td>\n",
       "      <td>1613.73</td>\n",
       "      <td>3084.59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5875</td>\n",
       "      <td>0.195833</td>\n",
       "      <td>30000</td>\n",
       "      <td>0.308067</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1810</td>\n",
       "      <td>0.154033</td>\n",
       "      <td>557.97</td>\n",
       "      <td>1041.66</td>\n",
       "      <td>4186.57</td>\n",
       "      <td>8.153604e+05</td>\n",
       "      <td>865.39</td>\n",
       "      <td>1956.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>249337</td>\n",
       "      <td>0.098618</td>\n",
       "      <td>2528312</td>\n",
       "      <td>0.481484</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120056</td>\n",
       "      <td>0.240742</td>\n",
       "      <td>110942.47</td>\n",
       "      <td>123540.02</td>\n",
       "      <td>292249.65</td>\n",
       "      <td>8.607989e+09</td>\n",
       "      <td>89437.53</td>\n",
       "      <td>352096.40</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>630771</td>\n",
       "      <td>0.249483</td>\n",
       "      <td>2528312</td>\n",
       "      <td>0.852889</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>537998</td>\n",
       "      <td>0.426444</td>\n",
       "      <td>198809.96</td>\n",
       "      <td>173656.13</td>\n",
       "      <td>463894.95</td>\n",
       "      <td>3.857394e+10</td>\n",
       "      <td>187256.88</td>\n",
       "      <td>610160.72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>314278</td>\n",
       "      <td>0.124303</td>\n",
       "      <td>2528312</td>\n",
       "      <td>0.956698</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>300681</td>\n",
       "      <td>0.478349</td>\n",
       "      <td>217297.85</td>\n",
       "      <td>176963.25</td>\n",
       "      <td>321473.10</td>\n",
       "      <td>2.155971e+10</td>\n",
       "      <td>157455.99</td>\n",
       "      <td>624699.01</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>778601</td>\n",
       "      <td>0.307953</td>\n",
       "      <td>2528312</td>\n",
       "      <td>0.788704</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>614109</td>\n",
       "      <td>0.394352</td>\n",
       "      <td>186692.35</td>\n",
       "      <td>170107.88</td>\n",
       "      <td>530418.45</td>\n",
       "      <td>4.403258e+10</td>\n",
       "      <td>199352.37</td>\n",
       "      <td>594840.84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>816401</td>\n",
       "      <td>0.322904</td>\n",
       "      <td>2528312</td>\n",
       "      <td>0.578538</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>472337</td>\n",
       "      <td>0.289269</td>\n",
       "      <td>140607.28</td>\n",
       "      <td>146090.61</td>\n",
       "      <td>547428.45</td>\n",
       "      <td>3.386656e+10</td>\n",
       "      <td>177130.52</td>\n",
       "      <td>482443.54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48000 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      left_cardinality  left_cardinality_ratio  base_cardinality  \\\n",
       "0                10800                0.360000             30000   \n",
       "1                 3265                0.108833             30000   \n",
       "2                 4860                0.162000             30000   \n",
       "3                 7892                0.263067             30000   \n",
       "4                 5875                0.195833             30000   \n",
       "...                ...                     ...               ...   \n",
       "1995            249337                0.098618           2528312   \n",
       "1996            630771                0.249483           2528312   \n",
       "1997            314278                0.124303           2528312   \n",
       "1998            778601                0.307953           2528312   \n",
       "1999            816401                0.322904           2528312   \n",
       "\n",
       "      selectivity_on_indexed_attr  left_ordered  base_ordered  result_size  \\\n",
       "0                        0.908900             0             1         9816   \n",
       "1                        0.671800             0             1         2193   \n",
       "2                        0.562533             0             1         2734   \n",
       "3                        0.692467             0             1         5465   \n",
       "4                        0.308067             0             1         1810   \n",
       "...                           ...           ...           ...          ...   \n",
       "1995                     0.481484             1             1       120056   \n",
       "1996                     0.852889             1             1       537998   \n",
       "1997                     0.956698             1             1       300681   \n",
       "1998                     0.788704             1             1       614109   \n",
       "1999                     0.578538             1             1       472337   \n",
       "\n",
       "      sel_on_indexed_attr_with_join_predicate  hj_idx_cost  hj_seq_cost  \\\n",
       "0                                    0.454467      3078.65      2821.50   \n",
       "1                                    0.335900      1188.48      1172.10   \n",
       "2                                    0.281267      1002.33      1142.52   \n",
       "3                                    0.346233      1237.22      1229.92   \n",
       "4                                    0.154033       557.97      1041.66   \n",
       "...                                       ...          ...          ...   \n",
       "1995                                 0.240742    110942.47    123540.02   \n",
       "1996                                 0.426444    198809.96    173656.13   \n",
       "1997                                 0.478349    217297.85    176963.25   \n",
       "1998                                 0.394352    186692.35    170107.88   \n",
       "1999                                 0.289269    140607.28    146090.61   \n",
       "\n",
       "      nl_idx_cost   nl_seq_cost  mj_idx_cost  mj_seq_cost  optimal_decision  \n",
       "0         5701.00  4.418208e+06      2197.32      3906.91                 4  \n",
       "1         3383.99  9.879785e+05      1207.18      2656.47                 1  \n",
       "2         3874.45  1.231189e+06      1170.05      2504.54                 0  \n",
       "3         4806.79  2.460164e+06      1613.73      3084.59                 1  \n",
       "4         4186.57  8.153604e+05       865.39      1956.25                 0  \n",
       "...           ...           ...          ...          ...               ...  \n",
       "1995    292249.65  8.607989e+09     89437.53    352096.40                 4  \n",
       "1996    463894.95  3.857394e+10    187256.88    610160.72                 1  \n",
       "1997    321473.10  2.155971e+10    157455.99    624699.01                 4  \n",
       "1998    530418.45  4.403258e+10    199352.37    594840.84                 1  \n",
       "1999    547428.45  3.386656e+10    177130.52    482443.54                 0  \n",
       "\n",
       "[48000 rows x 15 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "file_locations = {\n",
    "    'tpch': ['customer/orders_customer_optimal_rep.csv', 'orders/customer_orders_optimal_rep.csv', \n",
    "             'orders/lineitem_orders_optimal_rep.csv', 'part/lineitem_part_optimal_rep.csv', \n",
    "             'part/partsupp_part_optimal_rep.csv', 'partsupp/lineitem_partsupp_optimal_rep.csv', \n",
    "             'partsupp/part_partsupp_optimal_rep.csv', 'partsupp/supplier_partsupp_optimal_rep.csv', \n",
    "             'supplier/lineitem_supplier_optimal_rep.csv', 'supplier/partsupp_supplier_optimal_rep.csv'],\n",
    "    'imdb': ['cast_info/title_cast_info_optimal_rep.csv',\n",
    "             'movie_companies/title_movie_companies_optimal_rep.csv', 'movie_info/title_movie_info_optimal_rep.csv', \n",
    "             'movie_info_idx/title_movie_info_idx_optimal_rep.csv', 'movie_keyword/title_movie_keyword_optimal_rep.csv',\n",
    "             'title/cast_info_title_optimal_rep.csv', 'title/movie_companies_title_optimal_rep.csv',\n",
    "             'title/movie_info_idx_title_optimal_rep.csv', 'title/movie_info_title_optimal_rep.csv',\n",
    "             'title/movie_keyword_title_optimal_rep.csv'\n",
    "            ],\n",
    "    'ssb': ['customer/lineorder_customer_optimal_rep.csv', 'ddate/lineorder_ddate_optimal_rep.csv', \n",
    "           'part/lineorder_part_optimal_rep.csv', 'supplier/lineorder_supplier_optimal_rep.csv'\n",
    "           ]\n",
    "}\n",
    "\n",
    "\n",
    "datasets = ['ssb', 'tpch', 'imdb']\n",
    "\n",
    "\n",
    "\n",
    "dfs = []\n",
    "\n",
    "\n",
    "for d in datasets:\n",
    "    for f in file_locations[d]:\n",
    "        dfs.append(pd.read_csv(os.path.join(\"../data/\", d, f)))\n",
    "\n",
    "ds = pd.concat(dfs)\n",
    "ds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "m_regression_model = MLPRegressor\n",
    "m_classification_model = MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n"
     ]
    }
   ],
   "source": [
    "all_features = ['left_cardinality', 'base_cardinality',\n",
    "       'selectivity_on_indexed_attr', 'left_ordered', 'base_ordered',\n",
    "       'result_size', 'sel_on_indexed_attr_with_join_predicate']\n",
    "\n",
    "key_features = ['left_cardinality', 'base_cardinality', 'selectivity_on_indexed_attr']#,\n",
    "       #'result_size']\n",
    "\n",
    "features = all_features\n",
    "\n",
    "regression_targets = ['hj_idx_cost', 'hj_seq_cost', 'nl_idx_cost', 'nl_seq_cost', 'mj_idx_cost', 'mj_seq_cost']\n",
    "classification_target = ['optimal_decision']\n",
    "\n",
    "\n",
    "X = ds[features]\n",
    "y = ds['optimal_decision']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,random_state=1)\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "# scaler = preprocessing.StandardScaler().fit(X_test)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 95.97%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = m_classification_model(hidden_layer_sizes=(100, 100, 100, 100, 100),  max_iter=1000).fit(X_train, y_train)\n",
    "\n",
    "acc = np.sum(clf.predict(X_test) == y_test) / len(y_test)\n",
    "print(f\"Test accuracy: %.2f%%\" % (acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shap\n",
    "\n",
    "# x_ds_train = pd.DataFrame(data=X_train[0:100], columns=features)\n",
    "\n",
    "# explainer = shap.KernelExplainer(clf.predict, x_ds_train)\n",
    "# shap_values = explainer.shap_values(x_ds_train, nsamples=100)\n",
    "# shap.summary_plot(shap_values, x_ds_train, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n"
     ]
    }
   ],
   "source": [
    "# Collect all the regressors\n",
    "regressors = {}\n",
    "\n",
    "\n",
    "all_features = ['left_cardinality', 'base_cardinality',\n",
    "       'selectivity_on_indexed_attr', 'left_ordered', 'base_ordered',\n",
    "       'result_size', 'sel_on_indexed_attr_with_join_predicate']\n",
    "\n",
    "key_features = ['left_cardinality', 'base_cardinality',\n",
    "       'result_size']\n",
    "\n",
    "features = all_features\n",
    "\n",
    "regression_targets = ['hj_idx_cost', 'hj_seq_cost', 'nl_idx_cost', 'nl_seq_cost','mj_idx_cost', 'mj_seq_cost']\n",
    "classification_target = ['optimal_decision']\n",
    "\n",
    "\n",
    "X = ds[features]\n",
    "y = ds[regression_targets + classification_target]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hash join + index scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_y_train = np.log(y_train['hj_idx_cost'])\n",
    "c_y_test = y_test['hj_idx_cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgr = m_regression_model(hidden_layer_sizes=(100, 100, 100, 100, 100),  max_iter=1000).fit(X_train, c_y_train)\n",
    "regressors['hj_idx_cost'] = rgr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in percentage: +- 24.911710205261045%\n"
     ]
    }
   ],
   "source": [
    "loss_in_percentage = np.average(np.abs(np.exp(rgr.predict(X_test)) - c_y_test) / c_y_test)\n",
    "print(f\"Loss in percentage: +- {loss_in_percentage * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shap\n",
    "\n",
    "# x_ds_train = pd.DataFrame(data=X_train[0:100], columns=features)\n",
    "\n",
    "# explainer = shap.KernelExplainer(rgr.predict, x_ds_train)\n",
    "# shap_values = explainer.shap_values(x_ds_train, nsamples=100)\n",
    "# shap.summary_plot(shap_values, x_ds_train, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hash join + seq scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_y_train = np.log(y_train['hj_seq_cost'])\n",
    "c_y_test = y_test['hj_seq_cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in percentage: +- 18.756388003143865%\n"
     ]
    }
   ],
   "source": [
    "rgr = m_regression_model(hidden_layer_sizes=(100, 100, 100, 100, 100),  max_iter=1000).fit(X_train, c_y_train)\n",
    "regressors['hj_seq_cost'] = rgr\n",
    "loss_in_percentage = np.average(np.abs(np.exp(rgr.predict(X_test)) - c_y_test) / c_y_test)\n",
    "print(f\"Loss in percentage: +- {loss_in_percentage * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shap\n",
    "\n",
    "# x_ds_train = pd.DataFrame(data=X_train[0:100], columns=features)\n",
    "\n",
    "# explainer = shap.KernelExplainer(rgr.predict, x_ds_train)\n",
    "# shap_values = explainer.shap_values(x_ds_train, nsamples=100)\n",
    "# shap.summary_plot(shap_values, x_ds_train, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested loop + idx scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_y_train = np.log(y_train['nl_idx_cost'])\n",
    "c_y_test = y_test['nl_idx_cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in percentage: +- 24.230053289509147%\n"
     ]
    }
   ],
   "source": [
    "rgr = m_regression_model(hidden_layer_sizes=(100, 100, 100, 100, 100),  max_iter=1000).fit(X_train, c_y_train)\n",
    "regressors['nl_idx_cost'] = rgr\n",
    "loss_in_percentage = np.average(np.abs(np.exp(rgr.predict(X_test)) - c_y_test) / c_y_test)\n",
    "print(f\"Loss in percentage: +- {loss_in_percentage * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shap\n",
    "\n",
    "# x_ds_train = pd.DataFrame(data=X_train[0:100], columns=features)\n",
    "\n",
    "# explainer = shap.KernelExplainer(rgr.predict, x_ds_train)\n",
    "# shap_values = explainer.shap_values(x_ds_train, nsamples=100)\n",
    "# shap.summary_plot(shap_values, x_ds_train, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nested loop + seq scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_y_train = np.log(y_train['nl_seq_cost'])\n",
    "c_y_test = y_test['nl_seq_cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in percentage: +- 33.71482545857013%\n"
     ]
    }
   ],
   "source": [
    "rgr = m_regression_model(hidden_layer_sizes=(100, 100, 100, 100, 100),  max_iter=1000).fit(X_train, c_y_train)\n",
    "regressors['nl_seq_cost'] = rgr\n",
    "loss_in_percentage = np.average(np.abs(np.exp(rgr.predict(X_test)) - c_y_test) / c_y_test)\n",
    "print(f\"Loss in percentage: +- {loss_in_percentage * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shap\n",
    "\n",
    "# x_ds_train = pd.DataFrame(data=X_train[0:100], columns=features)\n",
    "\n",
    "# explainer = shap.KernelExplainer(rgr.predict, x_ds_train)\n",
    "# shap_values = explainer.shap_values(x_ds_train, nsamples=100)\n",
    "# shap.summary_plot(shap_values, x_ds_train, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge join + index scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_y_train = np.log(y_train['mj_idx_cost'])\n",
    "c_y_test = y_test['mj_idx_cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in percentage: +- 17.786062336333845%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rgr = m_regression_model(hidden_layer_sizes=(100, 100, 100, 100, 100),  max_iter=1000).fit(X_train, c_y_train)\n",
    "regressors['mj_idx_cost'] = rgr\n",
    "\n",
    "loss_in_percentage = np.average(np.abs(np.exp(rgr.predict(X_test)) - c_y_test) / c_y_test)\n",
    "print(f\"Loss in percentage: +- {loss_in_percentage * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shap\n",
    "\n",
    "# x_ds_train = pd.DataFrame(data=X_train[0:100], columns=features)\n",
    "\n",
    "# explainer = shap.KernelExplainer(rgr.predict, x_ds_train)\n",
    "# shap_values = explainer.shap_values(x_ds_train, nsamples=100)\n",
    "# shap.summary_plot(shap_values, x_ds_train, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge join + seq scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_y_train = np.log(y_train['mj_seq_cost'])\n",
    "c_y_test = y_test['mj_seq_cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in percentage: +- 30.354836128232055%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rgr = m_regression_model(hidden_layer_sizes=(100, 100, 100, 100, 100), max_iter=1000).fit(X_train, c_y_train)\n",
    "regressors['mj_seq_cost'] = rgr\n",
    "\n",
    "loss_in_percentage = np.average(np.abs(np.exp(rgr.predict(X_test)) - c_y_test) / c_y_test)\n",
    "print(f\"Loss in percentage: +- {loss_in_percentage * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shap\n",
    "\n",
    "# x_ds_train = pd.DataFrame(data=X_train[0:100], columns=features)\n",
    "\n",
    "# explainer = shap.KernelExplainer(rgr.predict, x_ds_train)\n",
    "# shap_values = explainer.shap_values(x_ds_train, nsamples=100)\n",
    "# shap.summary_plot(shap_values, x_ds_train, plot_type=\"bar\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Regression model to do classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy using all learned costs: 75.34%\n"
     ]
    }
   ],
   "source": [
    "predict_test = []\n",
    "operators = ['hj_idx_cost', 'hj_seq_cost', 'nl_idx_cost', 'nl_seq_cost','mj_idx_cost', 'mj_seq_cost']\n",
    "\n",
    "for op_idx, op in enumerate(operators) :\n",
    "    predict_test.append(regressors[op].predict(X_test))\n",
    "    \n",
    "results = np.stack(predict_test, axis=1)\n",
    "acc = np.sum(np.argmin(results, axis=1).reshape(-1,1).flatten() == y_test['optimal_decision'].to_numpy().flatten()) / len(y_test)\n",
    "print(\"Test accuracy using all learned costs: %.2f%%\" % (acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
