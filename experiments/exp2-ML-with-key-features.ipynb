{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "temporal-moses",
   "metadata": {},
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-relaxation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.DataLoader import *\n",
    "from core.models.MLP import * \n",
    "from core.models.GAM import *\n",
    "from core.models.SVM import *\n",
    "# from core.models.EBM import *\n",
    "\n",
    "from core.models.RandomForest import *\n",
    "from core.Visualizer import *\n",
    "from core.models.Classifier import *\n",
    "from core.models.XGB import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mobile-supplier",
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_clf_model_list ={\n",
    "    \"MLP\": MLPClassifier,\n",
    "    \"DT\": m_DecisionTreeClassifier,\n",
    "    \"RF\": m_RandomForestClassifier,\n",
    "    \"LR\": m_LogisticRegression,\n",
    "    \"SVM\": SVMClassifier,\n",
    "    \"XGB\": XGBOOSTClassifier\n",
    "}\n",
    "weighted_clf_model_name_list = ['MLP', 'RF(5)', 'RF(U)', 'DT(5)', 'DT(U)', 'LR', 'SVM', 'XGB']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clear-tradition",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-array",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = 'postgres' # postgres or mssql\n",
    "dl = DataLoader(engine)\n",
    "one_file_dss, one_file_names = dl.get_one_file_ds(return_type='ds and names', datasets=['ssb', 'tpch', 'tpch_10', 'tpch_100', 'imdb'])\n",
    "key_feature_set = ['sel_of_pred_on_indexed_attr', 'left_cardinality']    \n",
    "features = key_features[key_feature_set]\n",
    "print(\"Using features: \", features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minute-doubt",
   "metadata": {},
   "source": [
    "# Model accuracy with two features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personal-liechtenstein",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_accs = {\n",
    "    'MLP': [],\n",
    "    'RF(5)': [],\n",
    "    'RF(10)': [],\n",
    "    'RF(U)': [],\n",
    "    'DT(5)': [],\n",
    "    'DT(10)': [],\n",
    "    'DT(U)': [],\n",
    "    'LR': [],\n",
    "    'SVM': [],\n",
    "    'XGB': []\n",
    "}\n",
    "present_idxs = range(len(one_file_dss))\n",
    "\n",
    "for i in present_idxs:  # range(len(one_file_dss)):\n",
    "#     i = 0\n",
    "    print(f\"Processing: {i}\")\n",
    "    # ds = one_file_dss[i][one_file_dss[i]['predicate_op_num_on_non_indexed_attr'] == 0]\n",
    "    ds = one_file_dss[i]\n",
    "    ds_name = one_file_names[i]\n",
    "    \n",
    "    # =========================\n",
    "    X = ds[features]\n",
    "    y = ds['optimal_decision']\n",
    "    X_costs = ds[dl.regression_targets]\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn import preprocessing\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=1)\n",
    "    X_train_costs, _, _, _, = train_test_split(X_costs, y, train_size=0.8, random_state=1)\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "        X_train.to_numpy(),X_test.to_numpy(), y_train.to_numpy(), y_test.to_numpy()\n",
    "\n",
    "    X_train_weights = calculate_importance_from_costs(X_train_costs.to_numpy())\n",
    "\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "\n",
    "    # scaler = preprocessing.StandardScaler().fit(X_test)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    X_train_weights = preprocessing.MinMaxScaler().fit_transform(X_train_weights.reshape(-1,1)).flatten()\n",
    "    # =========================\n",
    "    \n",
    "    accs = []\n",
    "    for idx, model_name in enumerate(weighted_clf_model_name_list):\n",
    "        model = weighted_clf_model_list[model_name.split('(')[0]]        \n",
    "        if 'DT' in model_name or 'RF' in model_name:\n",
    "            max_depth = model_name.split('(')[-1].split(')')[0]\n",
    "            if max_depth.lower() == 'u':\n",
    "                max_depth = None\n",
    "            else:\n",
    "                max_depth = int(max_depth)\n",
    "            clf = model().fit(X_train, y_train, sample_weight=X_train_weights, max_depth=max_depth)\n",
    "        elif model_name == 'MLP':\n",
    "            clf = model().fit(X_train, y_train, sample_weight=X_train_weights, max_iter=500, weight_decay=0.000001)\n",
    "        else:\n",
    "            clf = model().fit(X_train, y_train, sample_weight=X_train_weights)\n",
    "            \n",
    "        print(f\"Accuray of {model}: {clf.score(X_test, y_test)}\")     \n",
    "        model_accs[model_name].append(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "negative-father",
   "metadata": {},
   "source": [
    "# Model accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "isolated-romance",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_accs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
