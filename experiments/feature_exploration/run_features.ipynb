{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.DataLoader import *\n",
    "from core.models.MLP import * \n",
    "from core.models.GAM import *\n",
    "from core.models.SVM import *\n",
    "from core.models.EBM import *\n",
    "from core.models.RandomForest import *\n",
    "from core.Visualizer import *\n",
    "from get_variable_name import *\n",
    "import itertools\n",
    "from multiprocessing import Pool\n",
    "import json\n",
    "\n",
    "def read_data(engine='postgres'):\n",
    "    dl = DataLoader(engine)\n",
    "    one_file_dss = dl.get_one_file_ds()\n",
    "    clustered_file_ds = dl.get_clustered_files_ds()\n",
    "    all_file_ds = dl.get_all_files_ds()\n",
    "    return one_file_dss, clustered_file_ds, all_file_ds\n",
    "\n",
    "class classification_model_runner():\n",
    "    def __init__(self, original_df):\n",
    "        self.df = original_df\n",
    "        self.models = {}\n",
    "        self.model_acc = {}\n",
    "\n",
    "    def set_dataframe(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def prepare_features(self, train_features, target_feature='optimal_decision', cost_features=DataLoader().regression_targets):\n",
    "        self.train_features = train_features\n",
    "        X = self.df[train_features]\n",
    "        y = self.df[target_feature]\n",
    "        X_costs = self.df[cost_features]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=1)\n",
    "        X_train_costs, _, _, _, = train_test_split(X_costs, y, train_size=0.8, random_state=1)\n",
    "        X_train, X_test, y_train, y_test = \\\n",
    "            X_train.to_numpy(),X_test.to_numpy(), y_train.to_numpy(), y_test.to_numpy()\n",
    "\n",
    "        X_train_weights = calculate_importance_from_costs(X_train_costs.to_numpy())\n",
    "\n",
    "        scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "\n",
    "        # scaler = preprocessing.StandardScaler().fit(X_test)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        X_train_weights = preprocessing.MinMaxScaler().fit_transform(X_train_weights.reshape(-1,1))\n",
    "\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.X_test = X_test\n",
    "        self.X_train_weights = X_train_weights\n",
    "        self.X_scaler = scaler\n",
    "        \n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        \n",
    "\n",
    "    def set_model_list(self, model_name_list):\n",
    "        self.model_name_list = model_name_list\n",
    "\n",
    "    def train_models(self):\n",
    "        for model_name in self.model_name_list:\n",
    "            if model_name == MLPClassifier:\n",
    "                clf = model_name(n_features=len(self.train_features))\n",
    "            elif model_name == sk_nn.MLPClassifier:\n",
    "                clf = model_name(hidden_layer_sizes=(100,100,100,100))\n",
    "            else:\n",
    "                clf = model_name()\n",
    "            clf = clf.fit(self.X_train, self.y_train)\n",
    "            acc = clf.score(self.X_test, self.y_test)\n",
    "#             print(f\"Accuray of {model_name}: {acc}\")\n",
    "            # if len(features) == 2:\n",
    "            #     plot_2d_decision_boundaries(clf, X_train, X_train_costs, y_train, title=f'{model} on {i}-th one table pair')\n",
    "            self.models[model_name] = clf\n",
    "            self.model_acc[model_name] = acc    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_file_dss, clustered_file_ds, all_file_ds = read_data()\n",
    "# all_dfs = [ds for ds in one_file_dss] + [clustered_file_ds, all_file_ds]\n",
    "all_dfs = [all_file_ds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = DataLoader().all_features\n",
    "model_name_list=[sk_nn.MLPClassifier, m_RandomForestClassifier,\n",
    "                          SVMClassifier, LinearGAMClassifier, EBMClassifier]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 455/455 [00:00<00:00, 225287.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "<class 'core.models.RandomForest.m_RandomForestClassifier'>\n",
      "<class 'core.models.SVM.SVMClassifier'>\n",
      "<class 'core.models.GAM.LinearGAMClassifier'>\n",
      "<class 'core.models.EBM.EBMClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py:933: FutureWarning: Passing attributes to check_is_fitted is deprecated and will be removed in 0.23. The attributes argument is ignored.\n",
      "  \"argument is ignored.\", FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/interpret/glassbox/ebm/ebm.py:801: UserWarning: Multiclass is still experimental. Subject to change per release.\n",
      "  warn(\"Multiclass is still experimental. Subject to change per release.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{('left_cardinality_ratio',\n",
       "  'left_cardinality',\n",
       "  'base_cardinality'): [0.7540833333333333]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "global performances\n",
    "\n",
    "\n",
    "def eval_features(train_features):\n",
    "    global performaces\n",
    "    accs = []\n",
    "    for ds in all_dfs:\n",
    "        runner = classification_model_runner(ds)\n",
    "        runner.prepare_features(list(train_features))\n",
    "        runner.set_model_list(model_name_list=model_name_list)\n",
    "        runner.train_models()\n",
    "        accs.append(np.average(list(runner.model_acc.values())))\n",
    "    performances[tuple(train_features)] = accs\n",
    "\n",
    "for n in [2]:\n",
    "    performances = {}\n",
    "    args = []\n",
    "\n",
    "    for train_features in tqdm(list(itertools.combinations(all_features, n))):\n",
    "        args.append(list(train_features))\n",
    "        \n",
    "    with Pool(50) as p:\n",
    "        p.map(eval_features, args)\n",
    "    with open(f'all_perfomances_{n}.json', 'w') as fp:\n",
    "        json.dump(performances, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('all_perfomances.json') as json_file:\n",
    "#     performances = json.load(json_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
